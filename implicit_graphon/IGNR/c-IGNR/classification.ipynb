{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9258fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedGroupKFold\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn import metrics\n",
    "\n",
    "device = 'mps' if torch.mps.is_available() else 'cpu'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from model_cIGNR import *\n",
    "from layers import *\n",
    "from siren_pytorch import *\n",
    "\n",
    "# warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0716ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MoleculeNet(root='data/', name='BBBP')\n",
    "train_idx, test_idx = train_test_split(range(len(dataset)), test_size=0.2, random_state=0)\n",
    "train_set = [dataset[i] for i in train_idx]\n",
    "test_set = [dataset[i] for i in test_idx]\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=10)\n",
    "test_loader = DataLoader(test_set, batch_size=10)\n",
    "\n",
    "atom_counts = [data.x.size(0) for data in dataset]\n",
    "\n",
    "# Basic stats\n",
    "num_molecules = len(atom_counts)\n",
    "min_atoms = min(atom_counts)\n",
    "max_atoms = max(atom_counts)\n",
    "\n",
    "n_card = max_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3cae25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_dim_hidden= [48,36,24]\n",
    "mlp_num_layer = len(mlp_dim_hidden)\n",
    "mlp_act = 'sine'\n",
    "emb_dim = 2\n",
    "gnn_num_layer = 3\n",
    "flag_emb = 1\n",
    "gnn_type = 'gin'\n",
    "\n",
    "latent_dim = 4\n",
    "gnn_layers = [2, 2, 2, latent_dim]\n",
    "\n",
    "\n",
    "snet = SirenNet(\n",
    "    dim_in = 2, # input [x,y] coordinate\n",
    "    dim_hidden = mlp_dim_hidden,\n",
    "    dim_out = 1, # output graphon (edge) probability \n",
    "    num_layers = mlp_num_layer, # f_theta number of layers\n",
    "    final_activation = 'sigmoid',\n",
    "    w0_initial = 30.,\n",
    "    activation = mlp_act)\n",
    "\n",
    "model = cIGNR(net=snet, input_card=n_card, emb_dim=emb_dim, latent_dim=latent_dim, num_layer=gnn_num_layer, device=device, flag_emb=flag_emb, gnn_type= gnn_type, gnn_layers=gnn_layers)\n",
    "\n",
    "p = \"/Users/berfininal/Documents/ML-proteins/implicit_graphon/IGNR/c-IGNR/Result/checkpoints/_checkpoint_dataset_bbbp_gin_dim_{latent_dim}.pt\"\n",
    "path = f\"/Users/berfininal/Documents/ML-proteins/implicit_graphon/IGNR/c-IGNR/Result/checkpoints/_checkpoint_dataset_bbbp_gin_dim_4.pt\"\n",
    "checkpoint = torch.load(path, map_location = 'cpu', weights_only = False)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "model = model.to(torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e8b667b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def encode_dataset(loader):\n",
    "    embeddings, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            x = model.encode(batch.x, batch.edge_index, batch.batch)\n",
    "            embeddings.append(x.cpu())\n",
    "            labels.extend(batch.y.cpu().numpy())\n",
    "    return torch.cat(embeddings).numpy(), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf9c32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = encode_dataset(train_loader)\n",
    "x_test, y_test = encode_dataset(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74512999",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4c2d617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7794117647058824\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(x_train, y_train)\n",
    "            \n",
    "acc = accuracy_score(y_test, svm.predict(x_test))\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b5eeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_cls(x_train, y_train):\n",
    "    \n",
    "    param_grid =  [{'kernel': ['rbf'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                     'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]},\n",
    "                    {'kernel': ['sigmoid'], 'gamma': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "                     'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000] },{'kernel': ['linear'], 'C': [0.001, 0.10, 0.1, 10, 25, 50, 100, 1000]}]              \n",
    "\n",
    "    t0 = time.time()\n",
    "    clf = GridSearchCV(SVC(), param_grid, cv=10,\n",
    "                        scoring='accuracy')\n",
    "\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    t = time.time() - t0\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print('Training accuracy')\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_estimator_)\n",
    "    print()\n",
    "    print()\n",
    "    print('****Results****')\n",
    "    svm_pred=clf.predict(x_train)\n",
    "    print(\"=\" * 52)\n",
    "    print(\"time cost: {}\".format(t))\n",
    "    print()\n",
    "    print(\"confusion matrix\\n\", metrics.confusion_matrix(y_train, svm_pred))\n",
    "    print()\n",
    "    print(\"\\t\\taccuracy: {}\".format(metrics.accuracy_score(y_train, svm_pred)))\n",
    "    print(\"\\t\\troc_auc_score: {}\".format(metrics.roc_auc_score(y_train, svm_pred)))\n",
    "    print(\"\\t\\tcohen_kappa_score: {}\".format(metrics.cohen_kappa_score(y_train, svm_pred)))\n",
    "    print()\n",
    "    print(\"\\t\\tclassification report\")\n",
    "    print(\"-\" * 52)\n",
    "    print(metrics.classification_report(y_train, svm_pred)) \n",
    "\n",
    "    test_acc = np.round(accuracy_score(y_test, clf.best_estimator_.predict(x_test)), 3)\n",
    "    print(f\"Test accuarcy : {test_acc}\")\n",
    "\n",
    "    return clf, svm_pred, y_test, x_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0dfd5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.001, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "\n",
      "Training accuracy\n",
      "0.7614955858147539\n",
      "SVC(C=0.001, gamma=0.01)\n",
      "\n",
      "\n",
      "****Results****\n",
      "====================================================\n",
      "time cost: 19.845431804656982\n",
      "\n",
      "confusion matrix\n",
      " [[   0  389]\n",
      " [   0 1242]]\n",
      "\n",
      "\t\taccuracy: 0.7614960147148988\n",
      "\t\troc_auc_score: 0.5\n",
      "\t\tcohen_kappa_score: 0.0\n",
      "\n",
      "\t\tclassification report\n",
      "----------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       389\n",
      "         1.0       0.76      1.00      0.86      1242\n",
      "\n",
      "    accuracy                           0.76      1631\n",
      "   macro avg       0.38      0.50      0.43      1631\n",
      "weighted avg       0.58      0.76      0.66      1631\n",
      "\n",
      "Test accuarcy : 0.779\n"
     ]
    }
   ],
   "source": [
    "clf, svm_pred, y_test, x_train, y_train = svm_cls(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1b2593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a05f9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train auroc : 0.5\n",
      "Test auroc : 0.5 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torcheval.metrics.functional import binary_auroc\n",
    "train_auroc = binary_auroc(torch.tensor(svm_pred), torch.tensor(y_train)[:,0])\n",
    "print(f\"train auroc : {train_auroc}\")\n",
    "print(f\"Test auroc : {binary_auroc(torch.tensor(clf.best_estimator_.predict(x_test)), torch.tensor(y_test)[:,0])} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542a824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "138e0b9f",
   "metadata": {},
   "source": [
    "#### MLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3bb57e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_in, hidden = [256, 128], p = 0.3):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        dims = [d_in] + hidden\n",
    "\n",
    "        for i in range(len(dims)-1):\n",
    "            layers += [nn.Linear(dims[i], dims[i+1]), nn.ReLU(), nn.Dropout(p)]\n",
    "        \n",
    "        layers += [nn.Linear(dims[-1], 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a264d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = torch.tensor(x_train, dtype=torch.float32)\n",
    "Xs = torch.tensor(x_test,  dtype=torch.float32)\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_test  = np.asarray(y_test)\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "yt = torch.tensor(y_train, dtype=torch.float32)\n",
    "ys = torch.tensor(y_test,  dtype=torch.float32)\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(TensorDataset(Xt, yt), batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(TensorDataset(Xs, ys), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "753e5be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    model = MLP(d_in = 2, hidden=[8], p = 0.3).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    criterion_tst = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay=1e-4)\n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "\n",
    "    for epoch in range(15):\n",
    "        model.train()\n",
    "        acc = 0\n",
    "        total = 0\n",
    "        for batch in train_loader:\n",
    "            x, y = batch\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits.view(-1,1), y)\n",
    "\n",
    "            pred = (torch.sigmoid(logits) >= 0.5).float()\n",
    "            acc += (pred == y).sum().item()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total +=loss.item() \n",
    "        \n",
    "        loss_test, acc_test = evaluate(model, test_loader, criterion=criterion_tst, device = device)\n",
    "        print(f\"Test loss : {loss_test}\")\n",
    "        print(f\"Test acc : {acc_test}\")\n",
    "\n",
    "\n",
    "        acc_total.append(float(np.round(acc/len(train_loader),3)))\n",
    "\n",
    "        loss_total.append(float(np.round(total/len(train_loader),3)))\n",
    "\n",
    "    print(f\"Accuracy : {acc_total}\")\n",
    "    print(f\"Loss total : {loss_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbdeb825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total=0\n",
    "    correct=0 \n",
    "    n=0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits.view(-1,1), y)\n",
    "\n",
    "        pred = (torch.sigmoid(logits) >= 0.5).float()\n",
    "        correct += (pred == y).sum().item()\n",
    "        \n",
    "        total += loss.item() \n",
    "    return total/len(test_loader), correct/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b8981d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 0.5616167972727519\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5313384656499072\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5250883276869611\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5181652547382727\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5161681378759989\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5150986528251229\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.51423025058537\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5136502461462487\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5121363488639273\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.515874486870882\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5126649929982859\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5123881163393579\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5112451442131182\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5113419832252875\n",
      "Test acc : 77.21951219512195\n",
      "Test loss : 0.5107574357492167\n",
      "Test acc : 77.21951219512195\n",
      "Accuracy : [65.53, 75.695, 75.732, 75.677, 75.677, 75.677, 75.732, 75.732, 75.732, 75.677, 75.677, 75.677, 75.732, 75.677, 75.732]\n",
      "Loss total : [0.644, 0.574, 0.565, 0.557, 0.56, 0.551, 0.552, 0.555, 0.554, 0.548, 0.549, 0.549, 0.555, 0.542, 0.552]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = MLP(d_in = 4, hidden=[8,16], p = 0.3).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion_tst = nn.BCEWithLogitsLoss()\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay=1e-4)\n",
    "loss_total = []\n",
    "acc_total = []\n",
    "\n",
    "for epoch in range(15):\n",
    "    model.train()\n",
    "    acc = 0\n",
    "    total = 0\n",
    "    for batch in train_loader:\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits.view(-1,1), y)\n",
    "\n",
    "        pred = (torch.sigmoid(logits) >= 0.5).float()\n",
    "        acc += (pred == y).sum().item()\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        total +=loss.item() \n",
    "    \n",
    "    loss_test, acc_test = evaluate(model, test_loader, criterion=criterion_tst, device = device)\n",
    "    print(f\"Test loss : {loss_test}\")\n",
    "    print(f\"Test acc : {acc_test}\")\n",
    "\n",
    "\n",
    "    acc_total.append(float(np.round(acc/len(train_loader),3)))\n",
    "\n",
    "    loss_total.append(float(np.round(total/len(train_loader),3)))\n",
    "\n",
    "print(f\"Accuracy : {acc_total}\")\n",
    "print(f\"Loss total : {loss_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed13b154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c95d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
